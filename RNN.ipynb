{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, LSTM, GRU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('data/data.csv')\n",
    "\n",
    "# Data normalization\n",
    "df['text'] = df['text'].str.lower()  # Convert text to lowercase\n",
    "tokenizer = Tokenizer(num_words=10000)  # Limit the number of words to keep\n",
    "tokenizer.fit_on_texts(df['text'])\n",
    "sequences = tokenizer.texts_to_sequences(df['text'])\n",
    "max_len = 500  # Set a maximum sequence length\n",
    "data = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "# Encode labels\n",
    "labels = pd.get_dummies(df['source']).values\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(data, labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RNN architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define three different RNN architectures\n",
    "def create_model(rnn_layer, units, activation, output_units, output_activation):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=10000, output_dim=100, input_length=max_len),\n",
    "        rnn_layer(units, activation=activation, return_sequences=False),\n",
    "        Dense(output_units, activation=output_activation)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Instantiate models\n",
    "model_1 = create_model(SimpleRNN, 50, 'relu', y_train.shape[1], 'sigmoid')\n",
    "model_2 = create_model(LSTM, 100, 'tanh', y_train.shape[1], 'sigmoid')\n",
    "model_3 = create_model(GRU, 150, 'relu', y_train.shape[1], 'sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models\n",
    "def train_and_save(model, name):\n",
    "    history = model.fit(X_train, y_train, epochs=10, validation_data=(X_validate, y_validate))\n",
    "    model.save(f'data/models/{name}.h5')\n",
    "    return history\n",
    "\n",
    "history1 = train_and_save(model_1, 'model_1')\n",
    "history2 = train_and_save(model_2, 'model_2')\n",
    "history3 = train_and_save(model_3, 'model_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation graphs\n",
    "def plot_history(history, title):\n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='validation accuracy')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history1, 'Model 1 Validation')\n",
    "plot_history(history2, 'Model 2 Validation')\n",
    "plot_history(history3, 'Model 3 Validation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
